{
  
    
        "post0": {
            "title": "A short tale on the longest day",
            "content": "I had forgotten the longest day fact. But now since 2017, around 21st June, I always notice in social media some news about it. Now to top up the excitement, I have my nephew who shares the birthday with summer solstice, and also two wonderful friends whose birthdays are one day before and one day after this day. . This time I read an exciting story shared by Vishu Guttal here. He describes his visit to a school and an excercise he did there on verifying this fact. I was amazed on reading it, and thought to do the excercise myself. This post is about it. . Astronomy is amazing. It amongst those few disciplines (in science) in which you are miles away from the entity you are studying. You can make theory, prediction, observations, and verification - but all this without ever getting close to the entity. This science has amazed humanity since centuries. Does earth go around the Sun? Is the orbit elliptical? Are there many galaxies? Is the universe expanding? Did all this start with a big bang? Theories have been made, disapproved, and updated. Let&#39;s take a small ride into this filed as we sit beside a computer and type few lines of codes, and verify - the &quot;longest day&quot; claim. . Lets first list does what we know: . Earth goes around Sun | This path is elliptic | Earth is tilted about its axis | . It is not easy to prove these three bullets. Spare a moment, and imagine staring at the sky, and verifying the above statements. It is not easy, and you will thank some amzing folks who did this. Further, as a result of these three bullets, we experience on Earth: . seasons | a longest day and a shortest day | . Thinking naively, season should be determined by length of the day. A longer day will imply more heat incident on the Earth surface, indicating a day in summer. The below figure from Wikipedia helps understanding this. The intersting thing note is that summer is not when earth is closest to the Sun. This is because of the tilt of the Earth. Owing to this tilt we have a day of the year on which the northern hemisphere is exposed to the Sun for maximum time, while the Earth rotates around its own axis. This day is called summer solstice. Similarly, we have a day of winter solstice - shortest day. So why did the Earth tilt? Long long time back something came flying by and hit Earth, and since then, our Earth got tilted. To read more click here. The nice thing is thus, we have seasons! . . In the code below we will do a small excercise to verify that there exists a longest day. We will do this for just one year, 2019. The samething can be done for any year if your are in doubt. The idea is simple. . Using python we will write few lines of codes and make some plots | The code will use a package &quot;astral&quot; to find the sunrise/sunset times for any latitude (and longitude) on Earth. | We will follow this up with some visualization | . Lets start with the code . # import some packages import pandas as pd import numpy as np import datetime import matplotlib.pyplot as plt import time from astral import LocationInfo from astral import sun import pytz from mpl_toolkits.axes_grid1 import make_axes_locatable # to move placement of colorbar from matplotlib.ticker import (MultipleLocator, FormatStrFormatter, AutoMinorLocator) . Step 1: We will load a CSV file which contains the latitude and longitude location of 212 cities in India. This is good as we can visulize the sunrise/sunset times across India, particularly, from East to West. . # load indian cities dataset df = pd.read_csv(&#39;./my_data/indian_cities_lat_long.csv&#39;) # sort rows from east to west (that is, longitude values) df = df.sort_values(&#39;lng&#39;,ascending=False) df = df.reset_index(drop=True) . Step 2: We will make a variable containing all dates of 2019 . # get all dates in 2019 start = datetime.datetime(2019, 1, 1, 0, 0, 0) end = datetime.datetime(2019, 12, 31, 0, 0, 0) delta = end - start . Step 3: We will call the astral package and compute the sunset/sunrise time for all 212 cities for all 365 days of 2019. . data = {} data[&#39;sunrise&#39;] = [] data[&#39;sunset&#39;] = [] data[&#39;noon&#39;] = [] for cnt in range(len(df)): data_sunset.append([]) data[&#39;sunrise&#39;].append([]) data[&#39;sunset&#39;].append([]) data[&#39;noon&#39;].append([]) i = 0 for day in range(delta.days + 1): t_start = time.time() this_date = str((start+datetime.timedelta(days=day)).date()) params = {&#39;lat&#39;:df[&#39;lat&#39;][cnt],&#39;lng&#39;:df[&#39;lng&#39;][cnt],&#39;date&#39;:this_date} tz = pytz.timezone(&#39;Asia/Kolkata&#39;) l = LocationInfo() l.name = &#39;name&#39; l.region = &#39;region&#39; l.latitude = df[&#39;lat&#39;][cnt] l.longitude = df[&#39;lng&#39;][cnt] s = sun.sun(l.observer, date=start+datetime.timedelta(days=day),tzinfo=tz) data[&#39;sunrise&#39;][cnt].append(s[&quot;sunrise&quot;].time().strftime(&#39;%H:%M:%S&#39;)) data[&#39;sunset&#39;][cnt].append(s[&quot;sunset&quot;].time().strftime(&#39;%H:%M:%S&#39;)) data[&#39;noon&#39;][cnt].append(s[&quot;noon&quot;].time().strftime(&#39;%H:%M:%S&#39;)) . Step 4: Some data structuring into numpy arrays to ease later visualization. . sun_rise_in_secs = [] sun_set_in_secs = [] sun_overhead_in_secs = [] sun_length_in_secs = [] for i in range(len(data[&#39;sunrise&#39;])): sun_rise_in_secs.append([]) sun_set_in_secs.append([]) sun_overhead_in_secs.append([]) sun_length_in_secs.append([]) for j in range(len(data[&#39;sunrise&#39;][0])): time_1 = data[&#39;sunrise&#39;][i][j].split(&#39;:&#39;) time_2 = data[&#39;sunset&#39;][i][j].split(&#39;:&#39;) time_3 = data[&#39;noon&#39;][i][j].split(&#39;:&#39;) sun_rise_in_secs[i].append(float(time_1[0])*60*60+float(time_1[1])*60+float(time_1[2])) sun_set_in_secs[i].append(float(time_2[0])*60*60+float(time_2[1])*60+float(time_2[2])) sun_overhead_in_secs[i].append(float(time_3[0])*60*60+float(time_3[1])*60+float(time_3[2])) sun_length_in_secs[i].append(sun_set_in_secs[i][j]-sun_rise_in_secs[i][j]) sun_rise_in_secs = np.array(sun_rise_in_secs) sun_set_in_secs = np.array(sun_set_in_secs) sun_overhead_in_secs = np.array(sun_overhead_in_secs) sun_length_in_secs = np.array(sun_length_in_secs) # np.argmax(daylength_in_secs,axis=1) . Visualization . First lets visualize the daylength, difference between sunset and sunrise times. . # plot daylength day_max = np.argmax(sun_length_in_secs,axis=1)+1 # date_max = [] # for i in range(len(day_max)): # date_max.append(datetime.datetime(2019, 1, 1) + datetime.timedelta(day_max[i] - 1)) fig, ax = plt.subplots(1,2,figsize=(16,5)) ax[0].plot([171,171],[9,15],&#39;--&#39;,color=&#39;red&#39;,linewidth=2,alpha=0.8) ax[0].plot([0,365],[12,12],&#39;--&#39;,color=&#39;green&#39;,linewidth=2,alpha=.8) ax[0].plot(sun_length_in_secs.T/60/60,alpha=0.4) ax[0].plot(sun_length_in_secs[0]/60/60,color=&#39;k&#39;,linewidth=5,label=df[&#39;city&#39;][0]) ax[0].plot(sun_length_in_secs[-1]/60/60,color=&#39;r&#39;,linewidth=5,label=df[&#39;city&#39;][len(df)-1]) ax[0].text(158,10,&#39;21st June&#39;,rotation=90) ax[0].set_xlabel(&quot;DAYS SINCE 1st JAN&quot;,fontsize=14) ax[0].set_ylabel(&quot;DAY LENGTH [in hrs]&quot;,fontsize=14) ax[0].grid(True) ax[0].spines[&#39;right&#39;].set_visible(False) ax[0].spines[&#39;top&#39;].set_visible(False) ax[0].xaxis.set_minor_locator(AutoMinorLocator()) ax[0].yaxis.set_minor_locator(AutoMinorLocator()) ax[0].tick_params(which=&#39;both&#39;, width=2) ax[0].tick_params(which=&#39;major&#39;, length=7) ax[0].tick_params(which=&#39;minor&#39;, length=4, color=&#39;gray&#39;) ax[0].legend() im = ax[1].imshow(sun_length_in_secs/60/60, cmap=&#39;RdBu_r&#39;) ax[1].set_xlabel(&quot;DAYS SINCE 1st JAN&quot;,fontsize=14) ax[1].set_ylabel(&quot;CITIES&quot;,fontsize=14) divider = make_axes_locatable(ax[1]) colorbar_ax = fig.add_axes([.92, 0.2, 0.01, 0.5]) cbar = fig.colorbar(im, cax=colorbar_ax) cbar.set_label(&#39;DAY LENGTH [in hrs]&#39;,size=13) ax[1].plot(day_max-1,np.arange(0,sun_length_in_secs.shape[0],1),&#39;o-&#39;,color=&#39;k&#39;) yticks = [0,50,100,150,200] keys = [] for i in range(len(yticks)): keys.append(df[&#39;city&#39;][yticks[i]]) ax[1].set_yticks(yticks) ax[1].set_yticklabels(keys,rotation=0,fontsize=13) plt.show() . You can see that there is a nice peak around 21st June for the day length data plotted for the 212 cities. For the majority of the cities this happens to be exactly 21st June. Here, Dibrugarh is the eastern most city in our database, and Porbander is the westtern most. The intersting is also the variation in the trace of day length across the cities. Also, note that there are two days of the year on which day length is excatly 12 hrs! These dates correspond to the equinox. . Next, lets visualize the sunrise times. The code is given below. . fig, ax = plt.subplots(1,2,figsize=(16,5)) ax[0].plot(sun_rise_in_secs.T/60/60,alpha=0.4) ax[0].plot(sun_rise_in_secs[0]/60/60,color=&#39;k&#39;,linewidth=5,label=df[&#39;city&#39;][0]) ax[0].plot(sun_rise_in_secs[-1]/60/60,color=&#39;r&#39;,linewidth=5,label=df[&#39;city&#39;][len(df)-1]) ax[0].set_xlabel(&quot;DAYS SINCE 1st JAN&quot;,fontsize=14) ax[0].set_ylabel(&quot;SUNRISE [in hrs]&quot;,fontsize=14) ax[0].grid(True) ax[0].spines[&#39;right&#39;].set_visible(False) ax[0].spines[&#39;top&#39;].set_visible(False) ax[0].xaxis.set_minor_locator(AutoMinorLocator()) ax[0].yaxis.set_minor_locator(AutoMinorLocator()) ax[0].tick_params(which=&#39;both&#39;, width=2) ax[0].tick_params(which=&#39;major&#39;, length=7) ax[0].tick_params(which=&#39;minor&#39;, length=4, color=&#39;gray&#39;) ax[0].legend() im = ax[1].imshow(sun_rise_in_secs/60/60, cmap=&#39;RdBu_r&#39;) ax[1].set_xlabel(&quot;DAYS SINCE 1st JAN&quot;,fontsize=14) ax[1].set_ylabel(&quot;CITIES&quot;,fontsize=14) divider = make_axes_locatable(ax[1]) colorbar_ax = fig.add_axes([.92, 0.2, 0.01, 0.5]) cbar = fig.colorbar(im, cax=colorbar_ax) cbar.set_label(&#39;SUNRISE [in hrs]&#39;,size=13) yticks = [0,50,100,150,200] keys = [] for i in range(len(yticks)): keys.append(df[&#39;city&#39;][yticks[i]]) ax[1].set_yticks(yticks) ax[1].set_yticklabels(keys,rotation=0,fontsize=13) plt.show() . In the above plots you can see a nice variation in sunrise times across the year. Further, the eastern most city sees an early sunrise compared to the western most. Also, sunrises early in summer and late in winter! . Next, lets visualiza the sunset times. The code snippet is given below. . fig, ax = plt.subplots(1,2,figsize=(16,5)) ax[0].plot(sun_set_in_secs.T/60/60,alpha=0.4) ax[0].plot(sun_set_in_secs[0]/60/60,color=&#39;k&#39;,linewidth=5,label=df[&#39;city&#39;][0]) ax[0].plot(sun_set_in_secs[-1]/60/60,color=&#39;r&#39;,linewidth=5,label=df[&#39;city&#39;][len(df)-1]) ax[0].set_xlabel(&quot;DAYS SINCE 1st JAN&quot;,fontsize=14) ax[0].set_ylabel(&quot;SUNSET TIME [in hrs]&quot;,fontsize=14) ax[0].grid(True) ax[0].spines[&#39;right&#39;].set_visible(False) ax[0].spines[&#39;top&#39;].set_visible(False) ax[0].xaxis.set_minor_locator(AutoMinorLocator()) ax[0].yaxis.set_minor_locator(AutoMinorLocator()) ax[0].tick_params(which=&#39;both&#39;, width=2) ax[0].tick_params(which=&#39;major&#39;, length=7) ax[0].tick_params(which=&#39;minor&#39;, length=4, color=&#39;gray&#39;) ax[0].legend() im = ax[1].imshow(sun_set_in_secs/60/60, cmap=&#39;RdBu_r&#39;) ax[1].set_xlabel(&quot;DAYS SINCE 1st JAN&quot;,fontsize=14) ax[1].set_ylabel(&quot;CITIES&quot;,fontsize=14) divider = make_axes_locatable(ax[1]) colorbar_ax = fig.add_axes([.92, 0.2, 0.01, 0.5]) cbar = fig.colorbar(im, cax=colorbar_ax) cbar.set_label(&#39;SUNSET [in hrs]&#39;,size=13) yticks = [0,50,100,150,200] keys = [] for i in range(len(yticks)): keys.append(df[&#39;city&#39;][yticks[i]]) ax[1].set_yticks(yticks) ax[1].set_yticklabels(keys,rotation=0,fontsize=13) plt.show() . Here again we see a nice pattern composed of a peak and a trough. . Next, lets plot the time of noon, or the time when the sun is at its highest point directly above the observer. Below is the code snippet to plot it. . fig, ax = plt.subplots(1,2,figsize=(16,5)) ax[0].plot(sun_overhead_in_secs.T/60/60,alpha=0.4) ax[0].plot(sun_overhead_in_secs[0]/60/60,color=&#39;k&#39;,linewidth=5,label=df[&#39;city&#39;][0]) ax[0].plot(sun_overhead_in_secs[-1]/60/60,color=&#39;r&#39;,linewidth=5,label=df[&#39;city&#39;][len(df)-1]) ax[0].set_xlabel(&quot;DAYS SINCE 1st JAN&quot;,fontsize=14) ax[0].set_ylabel(&quot;NOON [in hrs]&quot;,fontsize=14) ax[0].grid(True) ax[0].spines[&#39;right&#39;].set_visible(False) ax[0].spines[&#39;top&#39;].set_visible(False) ax[0].xaxis.set_minor_locator(AutoMinorLocator()) ax[0].yaxis.set_minor_locator(AutoMinorLocator()) ax[0].tick_params(which=&#39;both&#39;, width=2) ax[0].tick_params(which=&#39;major&#39;, length=7) ax[0].tick_params(which=&#39;minor&#39;, length=4, color=&#39;gray&#39;) ax[0].legend() im = ax[1].imshow(sun_overhead_in_secs/60/60, cmap=&#39;RdBu_r&#39;) ax[1].set_xlabel(&quot;DAYS SINCE 1st JAN&quot;,fontsize=14) ax[1].set_ylabel(&quot;CITIES&quot;,fontsize=14) divider = make_axes_locatable(ax[1]) colorbar_ax = fig.add_axes([.92, 0.2, 0.01, 0.5]) cbar = fig.colorbar(im, cax=colorbar_ax) cbar.set_label(&#39;NOON [in hrs]&#39;,size=13) yticks = [0,50,100,150,200] keys = [] for i in range(len(yticks)): keys.append(df[&#39;city&#39;][yticks[i]]) ax[1].set_yticks(yticks) ax[1].set_yticklabels(keys,rotation=0,fontsize=13) plt.show() . Here we see something which I didn&#39;t expect. India has one timezone and hence, we see a gradual increase in noon time from east to west. But what are those sinusoidal patterns, and also there is a downward moving trend. . That&#39;s it . We verified that there does exist a longest day around 21st June. For majority of the cities this day was 21st June, and for few others it was 20 or 22 June. Also, we did not verify here, but it appears that around 21st June the day lengths differ by few seconds. . | Twice is an year the day length is equal to the night length. . | The noon time varies across the year in a pattern which does seems interesting. . | . On top of this, I also find it interesting our we can estimate the sunrise/sunset/noon times using some math equations. There is a wiki article on this. I will try to know more on this sometime. As of know, I will like to thank the astral package for the implementation. I tried first using a free API but the query to get the data was tacking time in hrs. I will also like to than Vishu Guttal for sharing the nice initiative and also publishing it in Resonance, a Science Communication journal. .",
            "url": "https://neerajww.github.io/myblog/2020/06/22/summer_solstice.html",
            "relUrl": "/2020/06/22/summer_solstice.html",
            "date": " • Jun 22, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Escaping Praat scripting using python",
            "content": "What is Praat . Praat is a computer programme to analyze speech signals. The software interface provides a GUI allowing insightful visualization of features, such as pitch, formant, intensity, spectrogram, etc. On top of this, it also has a feature to write script enabling analysis of a pile of speech files. So, in short, it is a popular and useful research tool for speech analysis. But I haven&#39;t found the scripting language of Praat easy to understand. Actually, I have been scared to read the praat scripts also because the syntax looks alien to me. This is not to scare you as there are many people using it beautifully. . Parselmouth comes to rescue . Then one day I came across parselmouth, and this has given me some peace! Quating from its website: . Parselmouth is unique in its aim to provide a complete and Pythonic interface to the internal Praat code. While other projects either wrap Praat’s scripting language or reimplementing parts of Praat’s functionality in Python, Parselmouth directly accesses Praat’s C/C++ code (which means the algorithms and their output are exactly the same as in Praat) and provides efficient access to the program’s data, but also provides an interface that looks no different from any other Python library. . In this notebook I will provide some code snippets to analyze a speech file using parselmouth (and thus, praat). . Example . We will read a WAV file and extract some features. I must say that the package is still under development. You may not find all the features of praat implemented yet. But at the current stage itself I am finding it useful. . import numpy as np import parselmouth import matplotlib.pyplot as plt [fs, x] = wavfile.read(&#39;./my_sounds/count.wav&#39;) x = x/np.max(np.abs(x)) t = np.arange(0,len(x))/fs # for PRAAT sr = 16000 hop_dur = .01 num_form = 3 max_form_freq = 4500 # call parselmouth to load sound snd = parselmouth.Sound(&#39;./my_sounds/count.wav&#39;) # extract features pitch = snd.to_pitch(time_step=hop_dur) # pitch track harm = snd.to_harmonicity(time_step=hop_dur) # harmonic-to-noise ratio form = snd.to_formant_burg(time_step=hop_dur,max_number_of_formants=num_form, maximum_formant = max_form_freq, window_length=win_dur, pre_emphasis_from=50.0) # formants intensity = snd.to_intensity(minimum_pitch = 75.0, time_step=hop_dur,subtract_mean=False) # intensity spectrogram = snd.to_spectrogram(window_length=0.04) times = pitch.ts() # analysis window time instants pitch_vals = [] harm_vals = [] form_1_vals = [] form_2_vals = [] form_3_vals = [] inten_vals = [] for dt in times: pitch_vals.append(pitch.get_value_at_time(dt)) harm_vals.append(harm.get_value(dt)) form_1_vals.append(form.get_value_at_time(1,dt)) form_2_vals.append(form.get_value_at_time(2,dt)) form_3_vals.append(form.get_value_at_time(3,dt)) inten_vals.append(intensity.get_value(dt)) . /Users/neeks/miniconda2/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:5: WavFileWarning: Chunk (non-data) not understood, skipping it. &#34;&#34;&#34; . Lets visualize some of the features . fig = plt.subplots(figsize=(12,8)) ax = plt.subplot(2,2,1) ax.plot(times,pitch_vals) ax.set_xlabel(&#39;TIME [in s]&#39;) ax.set_ylabel(&#39;PITCH FREQ [in Hz]&#39;) plt.xticks(fontsize=13) plt.yticks(fontsize=13) plt.xlim(times[0],times[-1]) ax.grid(True) ax.spines[&#39;right&#39;].set_visible(False) ax.spines[&#39;top&#39;].set_visible(False) ax = plt.subplot(2,2,2) ax.plot(times,inten_vals) ax.set_xlabel(&#39;TIME [in s]&#39;) ax.set_ylabel(&#39;INTENSITY [in dB]&#39;) plt.xticks(fontsize=13) plt.yticks(fontsize=13) plt.xlim(times[0],times[-1]) ax.grid(True) ax.spines[&#39;right&#39;].set_visible(False) ax.spines[&#39;top&#39;].set_visible(False) ax = plt.subplot(2,2,3) ax.plot(times,harm_vals) ax.set_xlabel(&#39;TIME [in s]&#39;) ax.set_ylabel(&#39;HARMONIC-TO-NOISE RATIO [in dB]&#39;) plt.xlim(times[0],times[-1]) plt.xticks(fontsize=13) plt.yticks(fontsize=13) ax.grid(True) ax.spines[&#39;right&#39;].set_visible(False) ax.spines[&#39;top&#39;].set_visible(False) plt.ylim(0,50) ax = plt.subplot(2,2,4) ax.plot(times,np.array(form_1_vals)/1e3) ax.plot(times,np.array(form_2_vals)/1e3) ax.plot(times,np.array(form_3_vals)/1e3) ax.set_xlabel(&#39;TIME [in s]&#39;) ax.set_ylabel(&#39;FORMANT FREQ [in kHz]&#39;) plt.xlim(times[0],times[-1]) plt.xticks(fontsize=13) plt.yticks(fontsize=13) ax.grid(True) ax.spines[&#39;right&#39;].set_visible(False) ax.spines[&#39;top&#39;].set_visible(False) fig,ax = plt.subplots(1,1,figsize=(12,5)) dynamic_range = 70 X, Y = spectrogram.x_grid(), spectrogram.y_grid() sg_db = 10 * np.log10(spectrogram.values) im = ax.pcolormesh(X, Y, sg_db, vmin=sg_db.max() - dynamic_range, cmap=&#39;RdBu_r&#39;) fig.colorbar(im, ax=ax) plt.ylim([spectrogram.ymin, spectrogram.ymax]) plt.xlabel(&quot;TIME [in s]&quot;) plt.ylabel(&quot;FREQUENCY [in Hz]&quot;) . Text(0, 0.5, &#39;FREQUENCY [in Hz]&#39;) . Lets also interpret these features. . Pitch is a perceived acoustic feature which relates to the vibratory frequency of the vocal folds. | Intensity of the perceived correlate of loudness of speech | Harmonic-to-noise ratio relates to the quality of the speech, example, hoarse (low HNR) | Formant frequencies quantify the resonance frequecies of the vocal tract while we speak. You can read more about these features in the context of Praat at its website. | . Coming to the above plots, we can see that our speaker usually has a pitch close to 140 Hz. So we can bet the speaker is a male. The speaker is loud enough, and the HNR around 15 dB indicates a good quality speech. All these obaservations get further strengthened on seeing the narrowband spectrogram. . That&#39;s it . On top of these features you can also extract MFCCs, spectrogram, etc., do batch processing of files etc. You can learn about Parcelmouth usage here. Also, there is lot more here as well. . I hope you find this useful. .",
            "url": "https://neerajww.github.io/myblog/2020/06/16/PRAAT_feature_extractiion.html",
            "relUrl": "/2020/06/16/PRAAT_feature_extractiion.html",
            "date": " • Jun 16, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Polynomial regression using Gradient Descent",
            "content": "What is polynomial regression . Our friend Timmy gave us some data composed of input into a system and the corresponding output from the system. We will refer to the input as the independent variable (x) and the output as the dependent variable (y). We plot the data on an x versus y scatter plot. . The plot on the left looks neat. We know some high school mathematics and so start to wonder can we fit a polynomial to this data. That is, can we write y as follows: . $$y = sum_{p=1}^{P}a_{p}x^{p}+w$$ . where P is the order of the polynomial, a_p are the polynomial coefficients, and w is what could not be modeled by the polynomial (or noise). Examples of these fits are shown in the right plot. But why do we fit anything to the data given by Timmy? The simple answer is - we are curious and we know little math, and there are good tools at are service to do this. Remember, F. Gauss, the famous, also did this when he collected astronomy data, and his tools were much more laborious (pen and paper). Coming back, this curiosity may lead us to identify some relationship between input and output. What happens when you discover a relationship? The output does not looks random anymore, and given an input you can predict something close to what the system will output. Depending on the data you are trying to model (or Timmy gave), this can be amazing. It can help you understand the system or predict outputs and devise actions. . How is it done . Lets ask - How can when say the polynomial is a bad fit? In short, we have to first quantify what is good or bad here. Given an input x, we obtain the difference between the true output and polynomial model output. This is the error. The sign of the error is not a concern so we square this error. The squaring also make the error (as a function of input, a_p) a differentiable function. We sum this error over all N samples. That is, . $$E = sum_{n=1}^{N}(y[n]-y_{hat} [n])^2$$ $$y_{hat}[n]= sum_{p=1}^{P}a_{p}x^{p}[n]$$ . We will say the fit is good if the error is low. Again, low is qualitative, lower the better. But how much low is okay? Well, this depends on the application. . How will we do it here - Gradient Descent . We will use high school calculus, specifically, derivative. The derivative of a curve at any point gives the slope at that point. This is useful in many ways and particularly for our error function E, introduced above. The error function E is quadratic in a_p, and that means it is convex and reaches a minimum at a specific point in the multi-dimensional plane defined by a_ps. That&#39;s a good thing. We can start at any random point in this space, and compute derivative, and slide along the direction where the E decreases. This algorithm is referred to as gradient descent. Do read more about it - it is simple and quite powerful for wide varieties of problems. . We will use pytorch to implement this regresison using gradient descent. Lets start. I learnt this while listening to a course in fast.ai. . import numpy as np import torch import matplotlib.pyplot as plt from matplotlib.ticker import (MultipleLocator, FormatStrFormatter, AutoMinorLocator) import torch.nn as nn import torch.tensor as tensor . Create the dataset as a sum of a third degree polynomial and a little bit of uniform random noise. . # make the data n = 100 # number of samples of x x = torch.ones(n,4) # make a tensor x[:,0].uniform_(-1,1) # x x[:,1] = x[:,0]**2 x[:,2] = x[:,0]**3 a = tensor([1.,1,1,5]) # polynomial coefficients amax = 1 amin = -1 # create dataset y y = x@a + (amax-amin)*torch.rand(n)+amin # sum of polynomial and uniform random noise [-1,1] . So, Timmy has given us y and x. Let&#39;s visualize it on a scatter plot. We will also overlay on the scatter plot the samples from the underlying polynomial model governing this system. Ideally, we will like our polynomial regression to exactly match this polynomial model. If this happens then we have understood the system exactly. . fig = plt.subplots(figsize=(6,4)) ax = plt.subplot(1,1,1) ax.scatter(x[:,0],y,label=&#39;experiment samples&#39;) ax.scatter(x[:,0],x@a,label=&#39;underlying polynomial model samples&#39;) ax.grid(True) ax.spines[&#39;right&#39;].set_visible(False) ax.spines[&#39;top&#39;].set_visible(False) ax.tick_params(which=&#39;both&#39;, width=2) ax.tick_params(which=&#39;major&#39;, length=7) # ax.tick_params(which=&#39;minor&#39;, length=4, color=&#39;gray&#39;) ax.legend(loc=&#39;upper left&#39;,frameon=False,fontsize=14) plt.xticks(fontsize=13) plt.yticks(fontsize=13) ax.set_xlabel(&#39;x&#39;,fontsize=14) ax.set_ylabel(&#39;y (x)&#39;,fontsize=14) plt.tight_layout() . Implementation . # Lets implement the error function def mse(y_hat,y): return((y_hat-y)**2).mean() . # Lets initialize our polynomial model a_hat = torch.tensor([1.,1.,0,0]) a_hat = nn.Parameter(a_hat) . # Lets define our gradient descent updates accumulate_loss = [] def update(): y_hat = x@a_hat # estimate y_hat loss = mse(y,y_hat) # compute error or loss accumulate_loss.append(loss) # if t % 10 == 0: print(loss) loss.backward() # compute derivative/grad with respect to each parameter with torch.no_grad(): # deactivate backprop a_hat.sub_(lr*a_hat.grad) # gradient descent step a_hat.grad.zero_() # reset grads lr = 1e-2 # this is learning rate parameter, if curious, do google more on it for t in range(1000): update() . Lets visualize the loss curve over updates, and the estimated model overlaid on the true model. . fig = plt.subplots(figsize=(14,4)) ax = plt.subplot(1,2,1) ax.plot(np.array(accumulate_loss)*1e6) ax.grid(True) ax.spines[&#39;right&#39;].set_visible(False) ax.spines[&#39;top&#39;].set_visible(False) ax.tick_params(which=&#39;both&#39;, width=2) ax.tick_params(which=&#39;major&#39;, length=7) plt.xticks(fontsize=13) plt.yticks(fontsize=13) ax.set_xlabel(&#39;update index&#39;,fontsize=14) ax.set_ylabel(&#39;Loss x 1e6&#39;,fontsize=14) plt.tight_layout() ax = plt.subplot(1,2,2) ax.scatter(x[:,0],y,label=&#39;experiment samples&#39;) ax.scatter(x[:,0],x@a,label=&#39;underlying polynomial model samples&#39;) ax.scatter(x[:,0],x@a_hat.detach().numpy(),color=&#39;g&#39;,label=&#39;estimated polynomial model samples&#39;) ax.grid(True) ax.spines[&#39;right&#39;].set_visible(False) ax.spines[&#39;top&#39;].set_visible(False) ax.tick_params(which=&#39;both&#39;, width=2) ax.tick_params(which=&#39;major&#39;, length=7) # ax.tick_params(which=&#39;minor&#39;, length=4, color=&#39;gray&#39;) ax.legend(loc=&#39;upper left&#39;,frameon=False,fontsize=14) plt.xticks(fontsize=13) plt.yticks(fontsize=13) ax.set_xlabel(&#39;x&#39;,fontsize=14) ax.set_ylabel(&#39;y (x)&#39;,fontsize=14) plt.tight_layout() . From the above plots it is clear that we are headed in the descent direction (decresing loss or error). Further, our estimated polynomial model closely follows the underlying true polynomial model. . print(&#39;True model coefficients:&#39;) print(a.numpy()) print(&#39;Estimated model coefficients:&#39;) print(a_hat.detach().numpy()) . True model coefficients: [1. 1. 1. 5.] Estimated model coefficients: [1.1652924 0.9945537 0.5666001 5.0914917] . That&#39;s it . We saw that gradient descent can be used to estimate the coefficients of a linear regression model. Traditionally, polynomial regression is done using the Moore Penrose inverse. But we tried here using a NN approach and it too works and approximates the traditional solution. The flexibility here is we can use different differentiable error functions are obtain variants of the regression. .",
            "url": "https://neerajww.github.io/myblog/2020/06/15/polynomial_regress_GD.html",
            "relUrl": "/2020/06/15/polynomial_regress_GD.html",
            "date": " • Jun 15, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Implementing Fourier transform as a Neural Network",
            "content": "What is a Discrete Fourier transform (DFT) . I will start by assuming DFT is a black box. Our friend Tom has been kind enough to supply us with a dataset composed of inputs signals and corresponding output signals obtained from this black box. We know little bit about neural networks (NNs). So, lets use to model this black box. . Essentially, we will split the dataset given by Tommy into a train (80% samples) and a validation set (20% samples). Subsequently, using the training set we will train a NN to learn a mapping from input to output. The validation set will be used only for testing to verify if the mapping is generalizing to new data not seen by the NN during training. . (The idea presented here is something I asked Brandon Wu (the amazing!) to try on one day of his internship. Both of us jumped from our seats when we saw the matrix plot shown at the end). . Making the dataset . Let&#39;s get the data from Tom. . import numpy as np import matplotlib.pyplot as plt from numpy.fft import fft from matplotlib.ticker import (MultipleLocator, FormatStrFormatter, AutoMinorLocator) dim_signal = 256 dataset_samples = 5000 # 256x1 dimension white noise vectors data = [np.random.randn(1, dim_signal).T for _ in range(dataset_samples)] # real(DFT(data)) cosData = [np.real(fft(x,axis=0)) for x in data] cosData = np.array(cosData) cosData = cosData.reshape(cosData.shape[0], cosData.shape[1]) # imaginary(DFT(data)) sinData = [np.imag(fft(x,axis=0)) for x in data] sinData = np.array(sinData) sinData = sinData.reshape(sinData.shape[0], sinData.shape[1]) . Let&#39;s see an example from our dataset. . fig = plt.subplots(figsize=(16,3)) ax = plt.subplot(1,3,1) plt.plot(data[0],color=&#39;blue&#39;,label=&#39;SIGNAL&#39;) ax.set_xlabel(&#39;SAMPLE INDEX&#39;) ax.set_ylabel(&#39;A.U.&#39;) ax.grid(True) ax.spines[&#39;right&#39;].set_visible(False) ax.spines[&#39;top&#39;].set_visible(False) ax.xaxis.set_minor_locator(AutoMinorLocator()) ax.yaxis.set_minor_locator(AutoMinorLocator()) ax.tick_params(which=&#39;both&#39;, width=2) ax.tick_params(which=&#39;major&#39;, length=7) ax.tick_params(which=&#39;minor&#39;, length=4, color=&#39;gray&#39;) ax.legend(loc=&#39;lower right&#39;,frameon=False,fontsize=14) plt.xticks(fontsize=13) plt.yticks(fontsize=13) ax.figure.savefig(&#39;signal.pdf&#39;, bbox_inches=&#39;tight&#39;) ax = plt.subplot(1,3,2) plt.plot(cosData[0],color=&#39;red&#39;,label=&#39;REAL[DFT]&#39;) ax.set_xlabel(&#39;SAMPLE INDEX&#39;) ax.set_ylabel(&#39;A.U.&#39;) ax.grid(True) ax.spines[&#39;right&#39;].set_visible(False) ax.spines[&#39;top&#39;].set_visible(False) ax.xaxis.set_minor_locator(AutoMinorLocator()) ax.yaxis.set_minor_locator(AutoMinorLocator()) ax.tick_params(which=&#39;both&#39;, width=2) ax.tick_params(which=&#39;major&#39;, length=7) ax.tick_params(which=&#39;minor&#39;, length=4, color=&#39;gray&#39;) ax.legend(loc=&#39;lower right&#39;,frameon=False,fontsize=14) plt.xticks(fontsize=13) plt.yticks(fontsize=13) ax.figure.savefig(&#39;signal_DFT_real.pdf&#39;, bbox_inches=&#39;tight&#39;) ax = plt.subplot(1,3,3) plt.plot(sinData[0],color=&#39;green&#39;,label=&#39;IMAG[DFT]&#39;) ax.set_xlabel(&#39;SAMPLE INDEX&#39;) ax.set_ylabel(&#39;A.U.&#39;) ax.grid(True) ax.spines[&#39;right&#39;].set_visible(False) ax.spines[&#39;top&#39;].set_visible(False) ax.xaxis.set_minor_locator(AutoMinorLocator()) ax.yaxis.set_minor_locator(AutoMinorLocator()) ax.tick_params(which=&#39;both&#39;, width=2) ax.tick_params(which=&#39;major&#39;, length=7) ax.tick_params(which=&#39;minor&#39;, length=4, color=&#39;gray&#39;) ax.legend(loc=&#39;lower right&#39;,frameon=False,fontsize=14) plt.xticks(fontsize=13) plt.yticks(fontsize=13) ax.figure.savefig(&#39;signal_DFT_imag.pdf&#39;, bbox_inches=&#39;tight&#39;) plt.show() . Our Neural Network . The output of a DFT is a complex signal. We will model this as a sum of a real and an imaginary part. This way our NN will be dealing only with real values. . . Step 1: build the NN structure . # import pytorch packages import torch from torch.utils.data import Dataset, DataLoader from torch import nn from torch.autograd import Variable import time class fourier(nn.Module): def __init__(self): super(fourier, self).__init__() self.sinLayer = nn.Linear(256, 256) self.cosLayer = nn.Linear(256, 256) def forward(self, x): y1 = self.sinLayer(x) y2 = self.cosLayer(x) return y1, y2 class FourierDataset(Dataset): def __init__(self, data, output1, output2): indx = int(0.8 * len(data)) first = [(data[i], output1[i], output2[i]) for i in range(len(data)) if i &lt; indx] second = [(data[i], output1[i], output2[i]) for i in range(len(data)) if i &gt;= indx] self.data = first self.validation = second def __len__(self): return len(self.data) def __getitem__(self, idx): return self.data[idx] def nLoss(lossFun, one, two): print(1) loss = 0 for i in range(len(one)): print(2) loss += lossFun(one[i], two[i]).numpy() print(3) return loss . Step 2: Initialize the NN training parameters . num_epochs = 800 batch_size = 128 learning_rate = 1e-4 Fourier = fourier() dataset = FourierDataset(data, sinData, cosData) dataloader = DataLoader(dataset.data, batch_size=batch_size, shuffle=True) . optimizer = torch.optim.Adam( Fourier.parameters(), lr=learning_rate, weight_decay=1e-5) criterion = nn.MSELoss() losses = [] vlosses = [] regs = [] # make the validation data tensor validData = [] validSin = [] validCos = [] for dataIns in dataset.validation: validData.append(dataIns[0]) validSin.append(dataIns[1]) validCos.append(dataIns[2]) validSin = torch.from_numpy(np.array(validSin)) validCos = torch.from_numpy(np.array(validCos)) validData = torch.from_numpy(np.array(validData)) validData = validData.reshape(validData.shape[0],1,256) . Step 3: Train the NN using forward pass of training data and backward pass of trianing error updating the NN weights. This process is iterated num_epochs times. . # we will monitor a sample (indx) from the validation set examp_cos_output = [] examp_sin_output = [] indx = 10 weightSinLayer = [] # train the NN for num_epochs start_time = time.time() for epoch in range(num_epochs): for dataIns in dataloader: img, sinCorrect, cosCorrect = dataIns sinCorrect = sinCorrect.reshape(sinCorrect.shape[0], sinCorrect.shape[1]) cosCorrect = cosCorrect.reshape(cosCorrect.shape[0], cosCorrect.shape[1]) img = img.view(img.size(0), -1) img = img.reshape(img.shape[0],1,256) # ===================forward===================== sinOutput, cosOutput = Fourier(img.float()) loss1 = criterion(sinOutput.reshape(sinOutput.shape[0], sinOutput.shape[2]), sinCorrect.float()) loss2 = criterion(cosOutput.reshape(cosOutput.shape[0], cosOutput.shape[2]), cosCorrect.float()) loss = loss1 + loss2 # ===================backward==================== optimizer.zero_grad() loss.backward() optimizer.step() # ===================forward===================== sinOutput2, cosOutput2 = Fourier(validData.float()) loss1 = criterion(sinOutput2.reshape(sinOutput2.shape[0], sinOutput2.shape[2]), validSin.float()) loss2 = criterion(cosOutput2.reshape(cosOutput2.shape[0], cosOutput2.shape[2]), validCos.float()) vloss = loss1 + loss2 # ===================store loss================== losses.append(loss.data.numpy()) vlosses.append(vloss.data.numpy()) if epoch % 50 == 0: print(&#39;epoch [{}/{}], loss:{:.4f}, validation_loss:{:.4f}, time_elapsed:{:.4f}&#39; .format(epoch + 1, num_epochs, loss.data, vlosses[-1], time.time() - start_time)) if vlosses[-1] &lt;= 0.0001: print(vlosses[-1]) break # ===================store and example signal========== examp_cos_output.append(cosOutput2.detach().numpy()[indx]) examp_sin_output.append(sinOutput2.detach().numpy()[indx]) # =================== store the sine layer 256x256 weight matix ========== for i, param in enumerate(Fourier.parameters()): if i == 0: a = param.detach().numpy().copy() weightSinLayer.append(a) . epoch [1/800], loss:258.2382, validation_loss:255.5916, time_elapsed:0.1411 epoch [51/800], loss:196.6595, validation_loss:200.4876, time_elapsed:7.2933 epoch [101/800], loss:147.5006, validation_loss:154.0908, time_elapsed:14.3655 epoch [151/800], loss:110.7806, validation_loss:114.9219, time_elapsed:20.8714 epoch [201/800], loss:76.2455, validation_loss:82.2963, time_elapsed:27.5049 epoch [251/800], loss:51.3001, validation_loss:55.8251, time_elapsed:36.9585 epoch [301/800], loss:32.0512, validation_loss:35.1757, time_elapsed:46.5460 epoch [351/800], loss:17.3773, validation_loss:19.9666, time_elapsed:56.1011 epoch [401/800], loss:8.4049, validation_loss:9.6959, time_elapsed:65.5383 epoch [451/800], loss:2.8125, validation_loss:3.6714, time_elapsed:75.0106 epoch [501/800], loss:0.6671, validation_loss:0.9133, time_elapsed:84.1194 epoch [551/800], loss:0.0897, validation_loss:0.1225, time_elapsed:91.5053 epoch [601/800], loss:0.0154, validation_loss:0.0191, time_elapsed:97.9016 epoch [651/800], loss:0.0030, validation_loss:0.0049, time_elapsed:104.8059 epoch [701/800], loss:0.0009, validation_loss:0.0010, time_elapsed:112.0194 epoch [751/800], loss:0.0005, validation_loss:0.0005, time_elapsed:118.6301 . Let&#39;s visulaize the train and validation losses as a function of epoch counts. We will like this to decrease monotonically, and it indeed does so. This implies the NN is learning the mapping, and also generalizing it to the validations set. . FS = 14 fig, ax = plt.subplots(figsize=(7,4)) ax.plot(losses, label = &#39;TRANING LOSS&#39;) ax.plot(vlosses,color=&#39;orange&#39;,label=&#39;VALIDATION LOSS&#39;) ax.set_ylabel(&#39;MSE&#39;,fontsize=FS) ax.set_xlabel(&#39;EPOCH&#39;,fontsize=FS) ax.grid(True) ax.spines[&#39;right&#39;].set_visible(False) ax.spines[&#39;top&#39;].set_visible(False) ax.xaxis.set_minor_locator(AutoMinorLocator()) ax.yaxis.set_minor_locator(AutoMinorLocator()) ax.tick_params(which=&#39;both&#39;, width=2) ax.tick_params(which=&#39;major&#39;, length=7) ax.tick_params(which=&#39;minor&#39;, length=4, color=&#39;gray&#39;) ax.legend(loc=&#39;upper right&#39;,frameon=False,fontsize=14) plt.xticks(fontsize=13) plt.yticks(fontsize=13) plt.show() . Step 4: Lets also see an example signal to visualize the learnt fit on a signal sample from validation data. . fig = plt.subplots(figsize=(12, 3)) indx = 10 ax = plt.subplot(1,2,1) thisOutput = sinOutput.detach().numpy() thisCorrect = sinCorrect.detach().numpy() ax.plot(thisOutput[indx].T, label=&#39;output of network&#39;) ax.plot(thisCorrect[indx].T, color=&#39;orange&#39;, label=&#39;actual fft of data&#39;) ax.legend() ax.grid(True) ax.spines[&#39;right&#39;].set_visible(False) ax.spines[&#39;top&#39;].set_visible(False) ax.xaxis.set_minor_locator(AutoMinorLocator()) ax.yaxis.set_minor_locator(AutoMinorLocator()) ax.tick_params(which=&#39;both&#39;, width=2) ax.tick_params(which=&#39;major&#39;, length=7) ax.tick_params(which=&#39;minor&#39;, length=4, color=&#39;gray&#39;) ax.legend(loc=&#39;lower right&#39;,frameon=False,fontsize=14) plt.xticks(fontsize=13) plt.yticks(fontsize=13) ax = plt.subplot(1,2,2) thisOutput = cosOutput.detach().numpy() thisCorrect = cosCorrect.detach().numpy() ax.plot(thisOutput[indx].T, label=&#39;output of network&#39;) ax.plot(thisCorrect[indx].T, color=&#39;orange&#39;, label=&#39;actual fft of data&#39;) ax.legend() ax.grid(True) ax.spines[&#39;right&#39;].set_visible(False) ax.spines[&#39;top&#39;].set_visible(False) ax.xaxis.set_minor_locator(AutoMinorLocator()) ax.yaxis.set_minor_locator(AutoMinorLocator()) ax.tick_params(which=&#39;both&#39;, width=2) ax.tick_params(which=&#39;major&#39;, length=7) ax.tick_params(which=&#39;minor&#39;, length=4, color=&#39;gray&#39;) ax.legend(loc=&#39;lower right&#39;,frameon=False,fontsize=14) plt.xticks(fontsize=13) plt.yticks(fontsize=13) plt.show() . Lets also visualize how the NN approximates the mapping over epochs. We will take a signal from the validation set and plot it estimated DFT using NN over the epochs.Below is the gif. . . Below is the code snippet I used to generate the video to make the above gif. . Lets now understand the weight learnt by the NN. As this NN has no nonlinearity hence, visualizing the weights can give us a good understanding of what the NN is doing here. . fig, axes = plt.subplots(1, 2, figsize=(12, 7)) for i, param in enumerate(Fourier.parameters()): if i == 0: axes[0].imshow(param.detach().numpy(),cmap=&#39;RdBu_r&#39;,vmin=-1, vmax=1) axes[0].set_title(&#39;sine layer weight matrix&#39;) elif i == 2: pos = axes[1].imshow(param.detach().numpy(),cmap=&#39;RdBu_r&#39;,vmin=-1, vmax=1) axes[1].set_title(&#39;cosine layer weight matrix&#39;) fig.tight_layout() fig.subplots_adjust(right=0.8) cbar_ax = fig.add_axes([0.85, 0.25, 0.015, 0.5]) #(xloc,yloc,width,height) fig.colorbar(pos, cax=cbar_ax,ticks=[-1,-0.5,0,0.5,1]) plt.show() . A epoch-wise evolution of the sine layer weight matrix is shown below. . Lets see few columns of the sine and cosine matrix . fig, axes = plt.subplots(1, 2, figsize=(12, 4)) for i, param in enumerate(Fourier.parameters()): if i == 0: axes[0].plot(param.detach().numpy()[0],color=&#39;b&#39;) axes[0].plot(param.detach().numpy()[1],color=&#39;r&#39;) axes[0].plot(param.detach().numpy()[2],color=&#39;g&#39;) axes[0].set_title(&#39;sine matrix columns&#39;) axes[0].spines[&#39;right&#39;].set_visible(False) axes[0].spines[&#39;top&#39;].set_visible(False) elif i == 2: axes[1].plot(param.detach().numpy()[0],color=&#39;b&#39;) axes[1].plot(param.detach().numpy()[1],color=&#39;r&#39;) axes[1].plot(param.detach().numpy()[2],color=&#39;g&#39;) axes[1].set_title(&#39;cosine matrix columns&#39;) axes[1].spines[&#39;right&#39;].set_visible(False) axes[1].spines[&#39;top&#39;].set_visible(False) plt.show() . That&#39;s it . Each row in the above matrices are approximating the basis vectors corresponding to sine and cosine waves in traditional DFT matrix. Thus, the NN, learning a linear transformation here, converges to the unique solution, that is, the DFT matrix here. So we learnt that, . the DFT black box is composed of these matrices | the matrices are composed of sine and cosine signals | the MSE between traditional DFT and NN implementation decreases over epochs | . Appendices . # code for spectrum fit animation trueSpectrum = 10*np.log10(validCos.detach().numpy()[indx]**2+validSin.detach().numpy()[indx]**2) from matplotlib import animation, rc rc(&#39;animation&#39;,html=&#39;jshtml&#39;) fig = plt.figure(figsize=(7,4)) ax = plt.subplot(1,1,1) plt.plot(np.arange(0,256,1),trueSpectrum,color=&#39;b&#39;,label=&#39;TRUE&#39;) plt.xlabel(&#39;DFT BIN&#39;,fontsize=14) plt.ylabel(&#39;PSD [in dB]&#39;,fontsize=14) line, = plt.plot(np.arange(0,256,1),np.zeros((256,)),color=&#39;r&#39;,label=&#39;ESTIMATED&#39;) plt.grid(True) ax.spines[&#39;right&#39;].set_visible(False) ax.spines[&#39;top&#39;].set_visible(False) ax.legend(loc=&#39;lower right&#39;,frameon=False,fontsize=14) plt.xticks(fontsize=13) plt.yticks(fontsize=13) plt.close() def animate(i): outputSpectrum = 10*np.log10(examp_cos_output[i][0]**2+examp_sin_output[i][0]**2) line.set_ydata(outputSpectrum) return line, anim = animation.FuncAnimation(fig,animate,np.arange(0,400), interval=20) Writer = animation.writers[&#39;ffmpeg&#39;] writer = Writer(fps=10, metadata=dict(artist=&#39;Me&#39;), bitrate=1800) anim.save(&#39;anim_1.mp4&#39;, writer=writer) # code for matrix video import matplotlib.animation as animation # First set up the figure, the axis, and the plot element we want to animate fig = plt.figure( figsize=(5,5) ) im = plt.imshow(np.zeros((256,256)), aspect=&#39;auto&#39;, vmin=-1, vmax=1,cmap=&#39;RdBu_r&#39;) plt.title(&#39;sine layer wieght matrix over epochs&#39;) def animate_func(i): im.set_array(weightSinLayer[i]) return [im] anim = animation.FuncAnimation( fig, animate_func, frames = np.arange(0,799), interval = 20, # in ms ) anim.save(&#39;anim_2.mp4&#39;, fps=fps, extra_args=[&#39;-vcodec&#39;, &#39;libx264&#39;]) print(&#39;Done!&#39;) .",
            "url": "https://neerajww.github.io/myblog/2020/06/14/Fourier_network.html",
            "relUrl": "/2020/06/14/Fourier_network.html",
            "date": " • Jun 14, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "Tips for making plots",
            "content": "About . This python notebook is a demonstration of some simple codes to make neat plots. I have used these to make plots for my research papers. Some of my friends liked them so I thought to share some tips in this post. I will keep it short and to the point. Also, there are lots of amazing tutorials in the web to make wonderful plots with python. So, don&#39;t just stop here if you dont find what you are looking for. . A Line Plot . Let&#39;s start by plotting some data. . import numpy as np import matplotlib.pyplot as plt . mean, std = 0, 1 num_samples = 1000 y = np.random.normal(mean, std, size=num_samples) plt.plot(y) plt.show() . On staring the above plot for a minute you will easily spot several things which can be improved. The key is to know the terminology associated with the anatomy of a matplotlib plot. Once you know the terms, a simple searching on internet will help you how to incorporate anything you wish into this plot. So, here is the anotomy. . Let&#39;s improve the plot now. . # we import one more package to make minor ticks from matplotlib.ticker import (MultipleLocator, FormatStrFormatter, AutoMinorLocator) fig = plt.subplots(figsize=(16,5)) # (width_in_cms, height_in_cms) # plotting without any care ax = plt.subplot(1,2,1) ax.plot(y) # plotting wiith some care ax = plt.subplot(1,2,2) ax.plot(y) ax.set_xlabel(&#39;SAMPLE INDEX&#39;,fontsize=14) ax.set_ylabel(&#39;A.U.&#39;,fontsize=14) # A.U stands for Arbitrary Units ax.grid(True) ax.spines[&#39;right&#39;].set_visible(False) ax.spines[&#39;top&#39;].set_visible(False) ax.xaxis.set_minor_locator(AutoMinorLocator()) ax.yaxis.set_minor_locator(AutoMinorLocator()) ax.tick_params(which=&#39;both&#39;, width=2) ax.tick_params(which=&#39;major&#39;, length=7) ax.tick_params(which=&#39;minor&#39;, length=4, color=&#39;gray&#39;) plt.xticks(fontsize=13) plt.yticks(fontsize=13) plt.show() . A twin axis line plot . Let&#39;s see by plotting some data. We will also add the p-scrore comparing two bars. . # Create sin and cosine fs = 1000 t = np.arange(0,8000,1)/fs y1 = np.sin(t) y2 = np.cos(t) fig, ax1 = plt.subplots(figsize=(9,4)) color = &#39;tab:red&#39; ax1.set_xlabel(&#39;TIME [in secs]&#39;) ax1.set_ylabel(&#39;sin(t)&#39;, color=color, fontsize=14) ax1.plot(t,y1, color=color,alpha=0.7) # alpha controls the opacity ax1.tick_params(axis=&#39;y&#39;, labelcolor=color) ax1.spines[&#39;top&#39;].set_visible(False) ax1.grid(True) ax1.xaxis.set_minor_locator(AutoMinorLocator()) ax1.yaxis.set_minor_locator(AutoMinorLocator()) ax1.tick_params(which=&#39;both&#39;, width=2) ax1.tick_params(which=&#39;major&#39;, length=7) ax1.tick_params(which=&#39;minor&#39;, length=4, color=&#39;gray&#39;) plt.xticks(fontsize=13) plt.yticks(fontsize=13) # plt.xticks([0,31,60,91,len(sorteddates)-1], # [&#39;11 Jan&#39;,&#39;11 Feb&#39;,&#39;11 Mar&#39;,&#39;11 Apr&#39;,&#39;16 May 2020&#39;],rotation=0) ax2 = ax1.twinx() # instantiate a second axes that shares the same x-axis color = &#39;tab:blue&#39; ax2.set_ylabel(&#39;cos(t)&#39;, color=color,fontsize=14) # we already handled the x-label with ax1 ax2.plot(t,y2,color=color,alpha=0.5) ax2.tick_params(axis=&#39;y&#39;, labelcolor=color) ax2.spines[&#39;top&#39;].set_visible(False) ax1.grid(True) ax2.xaxis.set_minor_locator(AutoMinorLocator()) ax2.yaxis.set_minor_locator(AutoMinorLocator()) ax2.tick_params(which=&#39;both&#39;, width=2) ax2.tick_params(which=&#39;major&#39;, length=7) ax2.tick_params(which=&#39;minor&#39;, length=4, color=&#39;gray&#39;) plt.xticks(fontsize=13) plt.yticks(fontsize=13) # plt.xticks([0,31,60,91,len(sorteddates)-1], # [&#39;11 Jan&#39;,&#39;11 Feb&#39;,&#39;11 Mar&#39;,&#39;11 Apr&#39;,&#39;16 May 2020&#39;],rotation=0) fig.tight_layout() # otherwise the right y-label is slightly clipped plt.show() . A bar plot . Bar plots are useful when we have few variables to plot on x-axis and corresponding values in y-axis. Let&#39;s plot some. First we will define a function to annotate the p-value on top of the bars. . # First we will define a function to show significance values. # I pulled this from internet some time back and now can&#39;t find the reference. If you find do find it, let me know, I will like to add an acknowledgement. # funcs definitions to make significant plot markers def barplot_annotate_brackets(num1, num2, data, center, height, yerr=None, dh=.05, barh=.05, hdist=1,fs=None, maxasterix=None,fsize=14): &quot;&quot;&quot; Annotate barplot with p-values. :param num1: number of left bar to put bracket over :param num2: number of right bar to put bracket over :param data: string to write or number for generating asterixes :param center: centers of all bars (like plt.bar() input) :param height: heights of all bars (like plt.bar() input) :param yerr: yerrs of all bars (like plt.bar() input) :param dh: height offset over bar / bar + yerr in axes coordinates (0 to 1) :param barh: bar height in axes coordinates (0 to 1) :param fs: font size :param maxasterix: maximum number of asterixes to write (for very small p-values) &quot;&quot;&quot; if type(data) is str: text = data else: # * is p &lt; 0.05 # ** is p &lt; 0.005 # *** is p &lt; 0.0005 # etc. text = &#39;&#39; p = .05 while data &lt; p: text += &#39;*&#39; p /= 10. if maxasterix and len(text) == maxasterix: break if len(text) == 0: text = &#39;n. s.&#39; lx, ly = center[num1], height[num1] rx, ry = center[num2], height[num2] if yerr: ly += yerr[num1] ry += yerr[num2] ax_y0, ax_y1 = plt.gca().get_ylim() dh *= (ax_y1 - ax_y0) barh *= (ax_y1 - ax_y0) y = max(ly, ry) + dh barx = [lx, lx, rx, rx] bary = [y, y+barh, y+barh, y] mid = ((lx+rx)/2, y+barh+hdist) plt.plot(barx, bary, c=&#39;black&#39;) kwargs = dict(ha=&#39;center&#39;, va=&#39;bottom&#39;) if fs is not None: kwargs[&#39;fontsize&#39;] = fs plt.text(*mid, text, **kwargs,fontsize=fsize) . Now we will make the bar plot. . # make data x = [] x.append(np.random.normal(10, std, size=num_samples)) x.append(5+x[0]) # scatter plots fig = plt.subplots(figsize=(9, 4)) ax = plt.subplot(1,2,1) ax.scatter(x[0],x[1],color=&#39;green&#39;) ax.set_xlabel(&#39;VAR 1&#39;,fontsize=14) ax.set_ylabel(&#39;VAR 2&#39;,fontsize=14) ax.xaxis.set_minor_locator(AutoMinorLocator()) ax.yaxis.set_minor_locator(AutoMinorLocator()) ax.tick_params(which=&#39;both&#39;, width=2) ax.set_xlim(5,20) ax.set_ylim(5,20) ax.grid(True) plt.xticks(fontsize=13) plt.yticks(fontsize=13) ax.spines[&#39;right&#39;].set_visible(False) ax.spines[&#39;top&#39;].set_visible(False) # ax.plot([5,60],[5,60],&#39;--&#39;,color=&#39;black&#39;,alpha=0.25) ax.tick_params(which=&#39;minor&#39;, length=4, color=&#39;gray&#39;) ax = plt.subplot(1,2,2) ax.bar(2,np.mean(x[0]),yerr=np.std(x[0]), align=&#39;center&#39;,alpha=1, ecolor=&#39;black&#39;,capsize=5,hatch=&quot; &quot;,color=&#39;red&#39;,label=&#39;VAR 1&#39;,width=.5) ax.bar(4,np.mean(x[1]),yerr=np.std(x[1]), align=&#39;center&#39;,alpha=1, ecolor=&#39;black&#39;,capsize=5,hatch=&quot;//&quot;,color=&#39;blue&#39;,label=&#39;VAR 2&#39;,width=.5) ax.set_ylabel(&#39;AVERAGE&#39;,fontsize=14) ax.legend(loc=&#39;upper right&#39;,frameon=False,fontsize=14) plt.xticks([2,4], [&#39;VAR 1&#39;,&#39;VAR 2&#39;],rotation=0) ax.set_xlim(1,7) ax.set_ylim(5,19) plt.xticks(fontsize=13) plt.yticks(fontsize=13) ax.grid(True) ax.spines[&#39;right&#39;].set_visible(False) ax.spines[&#39;top&#39;].set_visible(False) # sns.despine() # Call the function barplot_annotate_brackets(0, 1, &#39;p = dummy&#39;, [2,4],[np.mean(x[0]),np.mean(x[1])], dh=.1,barh=.05,fsize=14) plt.tight_layout() plt.show() . A density plot . # here we will use the seaborn package import seaborn as sns sns.set() # Use seaborn&#39;s default style to make attractive graphs sns.set_style(&quot;white&quot;) sns.set_style(&quot;ticks&quot;) fig = plt.subplots(figsize=(8,3)) ax = plt.subplot(1,1,1) sns.distplot(x[0],label=&#39;VAR 1&#39;,color=&#39;red&#39;) sns.distplot(x[1],label=&#39;VAR 2&#39;,color=&#39;blue&#39;) # sns.kdeplot(np.reciprocal(rt_spkr_2[0]), shade=True,color=&#39;red&#39;,label=&#39;eng&#39;) ax.grid(True) ax.spines[&#39;right&#39;].set_visible(False) ax.spines[&#39;top&#39;].set_visible(False) ax.set_xlabel(&#39;A.U&#39;,fontsize=13) ax.set_ylabel(&#39;DENSITY&#39;,fontsize=13) ax.legend(loc=&#39;upper right&#39;,frameon=False,fontsize=13) plt.xticks(fontsize=13) plt.yticks(fontsize=13) plt.show() . A 2-D image or spectrogram plot . We will first read a sound file (WAV format). Then we will compute its spectrogram, and follow this up with plotting the time-domain signal and the spectrogram. . from scipy.io import wavfile # package to read WAV file from mpl_toolkits.axes_grid1 import make_axes_locatable # to move placement of colorbar # function to create spectrogram def generate_spectrogram(x,fs,wdur=20e-3,hdur=5e-3): X = [] i = 0 cnt = 0 win = np.hamming(wdur*fs) win = win - np.min(win) win = win/np.max(win) while i&lt;(len(x)-int(wdur*fs)): X.append(np.multiply(win,x[i:(i+int(wdur*fs))])) i = i + int(hdur*fs) cnt= cnt+1 X = np.array(X) Xs = abs(np.fft.rfft(X)) return Xs # read WAV file and plot data [fs, x] = wavfile.read(&#39;./my_sounds/count.wav&#39;) sig = x/np.max(np.abs(x)) taxis = np.arange(0,len(x))/fs fig = plt.subplots(figsize=(6,1)) ax = plt.subplot(1,1,1) ax.plot(taxis,sig) ax.set_xlim(taxis[0]-0.1/2,taxis[-1]) ax.set_ylim(-1,1) ax.set_xlabel(&#39;TIME [in s]&#39;) ax.set_ylabel(&#39;A.U&#39;) sns.despine(offset = .1,trim=False) # fmt=&#39;png&#39; # plt.savefig(path_store_figure+&#39;IIScConnect_sample_count_sig.&#39;+fmt, dpi=None, facecolor=&#39;w&#39;, edgecolor=&#39;w&#39;, # orientation=&#39;portrait&#39;, papertype=None, format=fmt,transparent=False, bbox_inches=&#39;tight&#39;, pad_inches=None, metadata=None) plt.show() fig, ax = plt.subplots(figsize=(6,4)) Xs = generate_spectrogram(sig,fs,wdur=25e-3,hdur=2.5e-3) XdB = 20*np.log10(Xs.T) XdB = XdB - np.max(XdB) im = ax.imshow(XdB,origin=&#39;lower&#39;,aspect=&#39;auto&#39;,extent = [taxis[0], taxis[-1], 0, fs/2/1e3], cmap=&#39;RdBu_r&#39;,vmin = 0, vmax =-100) divider = make_axes_locatable(ax) colorbar_ax = fig.add_axes([.95, 0.1, 0.015, 0.5]) fig.colorbar(im, cax=colorbar_ax) ax.set_xlim(taxis[0]-0.1/2,taxis[-1]) ax.set_ylim(-.1,4) ax.set_xlabel(&#39;TIME [in s]&#39;) ax.set_ylabel(&#39;FREQ [in kHz]&#39;) sns.despine(offset = 0.01,trim=False) # plt.savefig(path_store_figure+&#39;IIScConnect_sample_count_spectgm.&#39;+fmt, dpi=None, facecolor=&#39;w&#39;, edgecolor=&#39;w&#39;, # orientation=&#39;portrait&#39;, papertype=None, format=fmt,transparent=False, bbox_inches=&#39;tight&#39;, pad_inches=None, metadata=None) plt.show() . /Users/neeks/miniconda2/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:22: WavFileWarning: Chunk (non-data) not understood, skipping it. . A confusion matrix . cf_matrix = np.random.normal(0,1,(5,5)) keys = [&#39;A&#39;,&#39;B&#39;,&#39;C&#39;,&#39;D&#39;,&#39;E&#39;] fig = plt.subplots(figsize=(7,5)) ax = plt.subplot(1,1,1) # sns.set(font_scale=1.4)#for label size sns.heatmap(cf_matrix/np.sum(cf_matrix)*100, annot=True, fmt=&#39;.2g&#39;, cmap=&#39;Blues&#39;, annot_kws={&quot;size&quot;: 13}, cbar_kws={&#39;label&#39;: &#39;RANDOM NUMBERS&#39;})# font size ax.figure.axes[-1].yaxis.label.set_size(10) # fontsize for label on color bar ax.set_xticks(np.arange(len(keys))) ax.set_yticks(np.arange(len(keys))) ax.set_xticklabels(keys,rotation=0,fontsize=13) ax.set_yticklabels(keys,rotation=0,fontsize=13) plt.show() . Adding plot into a paper . The key here is to first create the plot at an aspect ratio as you will like it in the paper. I do this by setting the figsize to appropriate dimensions. . fig = plt.subplots(figsize=(6,4)) # (width_cms,height_cms) . You can also resize the figure in latex but that doesn&#39;t look very nice as the text and numbers inside the figure don&#39;t get appropriately scaled. From python, I save figure as PDF using: . ax.figure.savefig(&#39;name.pdf&#39;, bbox_inches=&#39;tight&#39;) . For more options, there is this: . fmt=&#39;pdf&#39; plt.savefig(&#39;name.&#39;+fmt, dpi=None, facecolor=&#39;w&#39;, edgecolor=&#39;w&#39;, orientation=&#39;portrait&#39;, papertype=None, format=fmt,transparent=False, bbox_inches=&#39;tight&#39;, pad_inches=None, metadata=None) . Sometimes I have to create multiple subplots and also block diagrams. For this I open Keynote (in Mac), and insert the plots (and make any block diagrams) in a slide. Then I export the slide as a PDF (saving in Best form). Subsequently, I crop the white spaces around the exported PDF using pdfcrop command in terminal. Done. . Adding plot into a slide or webpage . I guess JPEG is the smallest file size for a plot/figure. The downside is JPEG is not vector scalable graphics. When you zoom into a JPEG image you will loose on the resolution and see block artifacts, This is not there in PDF and EPS formats. Hence, PDF and EPS format suit academic papers and JPEG/PNG dont. However, JPEG and PNG are good for slides and webpages as you dont want a huge filesize here. . That&#39;s it! . What I presented is some simple codes to make neat plots. These plots are basic line/bar/distribution plots. The matplotlib is quite resourceful to make many more elegant plots. So, if you imagine something, the next step will be to know the term for it, and then see the documentation of matplotlib (or google it) and you may find a lead. .",
            "url": "https://neerajww.github.io/myblog/2020/06/11/plotting_tips.html",
            "relUrl": "/2020/06/11/plotting_tips.html",
            "date": " • Jun 11, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "Using Hilbert transform to get signal envelope",
            "content": "First we import some packages. . import numpy as np import scipy.signal as signal import matplotlib.pyplot as plt import seaborn as sns; sns.set() sns.set_style(&quot;white&quot;) sns.set_style(&quot;ticks&quot;) . Next, we define functions to create envelope and carrier signals. . def create_envelope(num_samples,fL_hz=100,N=1000,beta=3): # we will create the envelope by low pass filtering white noise mean = 0 std = 1 taps = signal.firwin(N, fL_hz/nyq_rate, window=(&#39;kaiser&#39;, beta)) x = np.random.normal(mean, std, size=num_samples) x = signal.filtfilt(taps, 1,x) x = (x-np.min(x)) x = x/np.max(x) return x def create_carrier_harmonic(fs=8e3,fc=200,num_samples=1000,ncomps=1): # this will create a harmonic carrier with ncomps harmonics x = [] for i in range(ncomps): x.append(np.sin(2*np.pi*(i+1)*fc*np.arange(0,num_samples,1)/fs)) x = sum(x) x = x/np.max(np.abs(x)) return x def create_carrier_noise(mean=0,std=1,num_samples=1000): # this will create a white noise carrier x = np.random.normal(mean, std, size=num_samples) x = x/np.abs(x) return x . Amplitude modulated tone . Let&#39;s start with an amplitude modulated tone and estimate the envelope. . # init filter and signal params fs = 8e3 dur = 5 # signal duration num_samples = int(dur*fs) t = np.arange(0,num_samples,1)/fs nyq_rate = fs / 2.0 width = 5.0/nyq_rate # 5 Hz filter transition width. ripple_db = 60.0 # stop band attenuation N, beta = signal.kaiserord(ripple_db, width) # create envelope fL_hz = 50 envelope = create_envelope(num_samples=num_samples,fL_hz=fL_hz,N=N,beta=beta) # create carrier carrier = create_carrier_harmonic(fs=fs,fc=100,num_samples=num_samples,ncomps=1) # create am-fm signal x = np.multiply(envelope,carrier) # estimate analytic signal ax = signal.hilbert(x) envelope_hat = np.abs(ax) # plt.plot(x) fig = plt.subplots(figsize=(8,4)) ax = plt.subplot(1,1,1) ax.plot(t,x,color=&#39;black&#39;,label=&#39;SIGNAL&#39;) ax.plot(t,envelope,color=&#39;blue&#39;,label=&#39;ENVP. TRUE&#39;) ax.plot(t,envelope_hat,color=&#39;red&#39;,label=&#39;ENVP. EST.&#39;) ax.set_xlabel(&#39;TIME [in s]&#39;) ax.set_ylabel(&#39;A.U.&#39;) ax.legend(loc=&#39;upper right&#39;,frameon=False,fontsize=12) plt.xticks(fontsize=13) plt.yticks(fontsize=13) ax.grid(True) ax.spines[&#39;right&#39;].set_visible(False) ax.spines[&#39;top&#39;].set_visible(False) plt.xlim(0,0.5) plt.ylim(-1,1.75) plt.show() . Amplitude modulated harmonics . Let&#39;s make the carrier a sum of 2 harmonics. The carrier is not a tone but a sum of two tones. . # init filter and signal params fs = 8e3 dur = 5 # signal duration num_samples = int(dur*fs) t = np.arange(0,num_samples,1)/fs nyq_rate = fs / 2.0 width = 5.0/nyq_rate # 5 Hz filter transition width. ripple_db = 60.0 # stop band attenuation N, beta = signal.kaiserord(ripple_db, width) # create envelope fL_hz = 50 envelope = create_envelope(num_samples=num_samples,fL_hz=fL_hz,N=N,beta=beta) # create carrier carrier = create_carrier_harmonic(fs=fs,fc=100,num_samples=num_samples,ncomps=2) # create am-fm signal x = np.multiply(envelope,carrier) # estimate analytic signal ax = signal.hilbert(x) envelope_hat = np.abs(ax) # plt.plot(x) fig = plt.subplots(figsize=(8,4)) ax = plt.subplot(1,1,1) ax.plot(t,x,color=&#39;black&#39;,label=&#39;SIGNAL&#39;) ax.plot(t,envelope,color=&#39;blue&#39;,label=&#39;ENVP. TRUE&#39;) ax.plot(t,envelope_hat,color=&#39;red&#39;,label=&#39;ENVP. EST.&#39;) ax.set_xlabel(&#39;TIME [in s]&#39;) ax.set_ylabel(&#39;A.U.&#39;) ax.legend(loc=&#39;upper right&#39;,frameon=False,fontsize=12) plt.xticks(fontsize=13) plt.yticks(fontsize=13) ax.grid(True) ax.spines[&#39;right&#39;].set_visible(False) ax.spines[&#39;top&#39;].set_visible(False) plt.xlim(0,0.5) plt.ylim(-.5,1) plt.show() . The envelope estimated is a poor fit to the true envelope. Can we improve this? One option is to apply a lowpass filter to the estimated envelope. Lets see how does it do. . # init filter and signal params fs = 8e3 dur = 5 # signal duration num_samples = int(dur*fs) t = np.arange(0,num_samples,1)/fs nyq_rate = fs / 2.0 width = 5.0/nyq_rate # 5 Hz filter transition width. ripple_db = 60.0 # stop band attenuation N, beta = signal.kaiserord(ripple_db, width) # create envelope fL_hz = 50 envelope = create_envelope(num_samples=num_samples,fL_hz=fL_hz,N=N,beta=beta) # create carrier carrier = create_carrier_harmonic(fs=fs,fc=100,num_samples=num_samples,ncomps=2) # create am-fm signal x = np.multiply(envelope,carrier) # estimate analytic signal ax = signal.hilbert(x) envelope_hat = np.abs(ax) taps = signal.firwin(N, fL_hz/nyq_rate, window=(&#39;kaiser&#39;, beta)) envelope_hat_filt = signal.filtfilt(taps, 1,envelope_hat) fig = plt.subplots(figsize=(16,4)) ax = plt.subplot(1,2,1) ax.plot(t,x,color=&#39;black&#39;,label=&#39;SIGNAL&#39;) ax.plot(t,envelope,color=&#39;blue&#39;,label=&#39;ENVP. TRUE&#39;) ax.plot(t,envelope_hat,color=&#39;red&#39;,label=&#39;ENVP. EST.&#39;) ax.set_xlabel(&#39;TIME [in s]&#39;) ax.set_ylabel(&#39;A.U.&#39;) ax.legend(loc=&#39;upper right&#39;,frameon=False,fontsize=12) plt.xticks(fontsize=13) plt.yticks(fontsize=13) ax.grid(True) ax.spines[&#39;right&#39;].set_visible(False) ax.spines[&#39;top&#39;].set_visible(False) plt.xlim(0,0.5) plt.ylim(-.5,1) ax = plt.subplot(1,2,2) ax.plot(t,x,color=&#39;black&#39;,label=&#39;SIGNAL&#39;) ax.plot(t,envelope,color=&#39;blue&#39;,label=&#39;ENVP. TRUE&#39;) ax.plot(t,envelope_hat_filt,color=&#39;red&#39;,label=&#39;ENVP. EST. FILT.&#39;) ax.set_xlabel(&#39;TIME [in s]&#39;) ax.set_ylabel(&#39;A.U.&#39;) ax.legend(loc=&#39;upper right&#39;,frameon=False,fontsize=12) plt.xticks(fontsize=13) plt.yticks(fontsize=13) ax.grid(True) ax.spines[&#39;right&#39;].set_visible(False) ax.spines[&#39;top&#39;].set_visible(False) plt.xlim(0,0.5) plt.ylim(-.5,1) plt.show() . Amplitude modulated white noise . We do better with filter but still not perfect. Now, lets make the carrier a broadband white noise instead of tones. . # init filter and signal params fs = 8e3 dur = 5 # signal duration num_samples = int(dur*fs) t = np.arange(0,num_samples,1)/fs nyq_rate = fs / 2.0 width = 5.0/nyq_rate # 5 Hz filter transition width. ripple_db = 60.0 # stop band attenuation N, beta = signal.kaiserord(ripple_db, width) # create envelope fL_hz = 50 envelope = create_envelope(num_samples=num_samples,fL_hz=fL_hz,N=N,beta=beta) # create carrier carrier = create_carrier_noise(mean=0,std=1,num_samples=num_samples) # create am-fm signal x = np.multiply(envelope,carrier) # estimate analytic signal ax = signal.hilbert(x) envelope_hat = np.abs(ax) taps = signal.firwin(N, fL_hz/nyq_rate, window=(&#39;kaiser&#39;, beta)) envelope_hat_filt = signal.filtfilt(taps, 1,envelope_hat) fig = plt.subplots(figsize=(16,4)) ax = plt.subplot(1,2,1) ax.plot(t,x,color=&#39;black&#39;,label=&#39;SIGNAL&#39;) ax.plot(t,envelope,color=&#39;blue&#39;,label=&#39;ENVP. TRUE&#39;) ax.plot(t,envelope_hat,color=&#39;red&#39;,label=&#39;ENVP. EST.&#39;) ax.set_xlabel(&#39;TIME [in s]&#39;) ax.set_ylabel(&#39;A.U.&#39;) ax.legend(loc=&#39;upper right&#39;,frameon=False,fontsize=12) plt.xticks(fontsize=13) plt.yticks(fontsize=13) ax.grid(True) ax.spines[&#39;right&#39;].set_visible(False) ax.spines[&#39;top&#39;].set_visible(False) plt.xlim(0,0.5) plt.ylim(-2,2) ax = plt.subplot(1,2,2) ax.plot(t,x,color=&#39;black&#39;,label=&#39;SIGNAL&#39;) ax.plot(t,envelope,color=&#39;blue&#39;,label=&#39;ENVP. TRUE&#39;) ax.plot(t,envelope_hat_filt,color=&#39;red&#39;,label=&#39;ENVP. EST. FILT.&#39;) ax.set_xlabel(&#39;TIME [in s]&#39;) ax.set_ylabel(&#39;A.U.&#39;) ax.legend(loc=&#39;upper right&#39;,frameon=False,fontsize=12) plt.xticks(fontsize=13) plt.yticks(fontsize=13) ax.grid(True) ax.spines[&#39;right&#39;].set_visible(False) ax.spines[&#39;top&#39;].set_visible(False) plt.xlim(0,0.5) plt.ylim(-2,2) plt.show() . Again, we see that filtered envelope is a better estimate. Now let&#39;s use this approach to obtain an envelope of speech signal. . Speech signal . from scipy.io import wavfile # package to read WAV file # read WAV file and plot data [fs, x] = wavfile.read(&#39;./my_sounds/count.wav&#39;) x = x/np.max(np.abs(x)) t = np.arange(0,len(x))/fs # get analytic signal ax = signal.hilbert(x) envelope_hat = np.abs(ax) taps = signal.firwin(N, fL_hz/nyq_rate, window=(&#39;kaiser&#39;, beta)) envelope_hat_filt = signal.filtfilt(taps, 1,envelope_hat) fig = plt.subplots(figsize=(16,4)) ax = plt.subplot(1,2,1) ax.plot(t,x,color=&#39;black&#39;,label=&#39;SIGNAL&#39;) ax.plot(t,envelope_hat,color=&#39;red&#39;,label=&#39;ENVP. EST.&#39;) ax.set_xlabel(&#39;TIME [in s]&#39;) ax.set_ylabel(&#39;A.U.&#39;) ax.legend(loc=&#39;upper right&#39;,frameon=False,fontsize=12) plt.xticks(fontsize=13) plt.yticks(fontsize=13) ax.grid(True) ax.spines[&#39;right&#39;].set_visible(False) ax.spines[&#39;top&#39;].set_visible(False) # plt.xlim(0,0.5) plt.ylim(-1,1.5) ax = plt.subplot(1,2,2) ax.plot(t,x,color=&#39;black&#39;,label=&#39;SIGNAL&#39;) ax.plot(t,envelope_hat_filt,color=&#39;red&#39;,label=&#39;ENVP. EST. FILT.&#39;) ax.set_xlabel(&#39;TIME [in s]&#39;) ax.set_ylabel(&#39;A.U.&#39;) ax.legend(loc=&#39;upper right&#39;,frameon=False,fontsize=12) plt.xticks(fontsize=13) plt.yticks(fontsize=13) ax.grid(True) ax.spines[&#39;right&#39;].set_visible(False) ax.spines[&#39;top&#39;].set_visible(False) # plt.xlim(0,0.5) plt.ylim(-1,1.5) plt.show() . /Users/neeks/miniconda2/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:4: WavFileWarning: Chunk (non-data) not understood, skipping it. after removing the cwd from sys.path. . Before we sum-up complete lets see how good is our filter. We will apply it on white noise and see the resulting spectrum before and after application. . # plot signal and spectrum x = np.random.normal(0,1,size=num_samples) y = signal.filtfilt(taps, 1,x) fig = plt.subplots(figsize=(16,4)) ax = plt.subplot(1,2,1) ax.plot(np.arange(0,num_samples//2+1,1)/num_samples*fs,10*np.log(abs(np.fft.rfft(x))),label=&#39;SIGNAL&#39;) ax.plot(np.arange(0,num_samples//2+1,1)/num_samples*fs,10*np.log(abs(np.fft.rfft(y))),label=&#39;SIGNAL FILTERED&#39;) ax.grid(True) ax.spines[&#39;right&#39;].set_visible(False) ax.spines[&#39;top&#39;].set_visible(False) ax.set_xlabel(&#39;FREQUENCY [in Hz]&#39;,fontsize=14) ax.set_ylabel(&#39;SPECTRUM [in dB]&#39;,fontsize=14) ax.legend(loc=&#39;upper right&#39;,frameon=False,fontsize=12) plt.ylim(10,80) plt.xticks(fontsize=13) plt.yticks(fontsize=13) ax = plt.subplot(1,2,2) ax.plot(taps) ax.grid(True) ax.spines[&#39;right&#39;].set_visible(False) ax.spines[&#39;top&#39;].set_visible(False) ax.set_xlabel(&#39;taps&#39;,fontsize=14) ax.set_ylabel(&#39;A.U.&#39;,fontsize=14) ax.legend(loc=&#39;upper right&#39;,frameon=False,fontsize=12) plt.xticks(fontsize=13) plt.yticks(fontsize=13) plt.show() . No handles with labels found to put in legend. . From the plot it is clear that FIR filter does a good job in removing the spectrum beyond 50 Hz. Lets visualize the filter response and spectrum. . That&#39;s it! . To sum it up, assuming you went through the above, we now understand that . Hilbert transform can be used to estimate signal envelope | The estimation is very accurate for tone signals. In general, it is accurate for narrowband carrier signals. | The estimation performance degrades for wideband carriers, like sum of tones or white noise (broadband signal). | The estimation performance improves on applying a lowpass filter to the envelope estimate. | Such lowpass filtering of the envelope estimate can be also applied to speech signals. | . The above observations can be reasoned from a theoretical angle. I will try to do it another post. .",
            "url": "https://neerajww.github.io/myblog/2020/06/11/hilbert_transform.html",
            "relUrl": "/2020/06/11/hilbert_transform.html",
            "date": " • Jun 11, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Hi, to know about me you can click here. . This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://neerajww.github.io/myblog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://neerajww.github.io/myblog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}